version: '3.8'

services:

  devcontainer:
    build:
      context: .
      dockerfile: devcontainer.Dockerfile
    command: /bin/sh -c "sleep infinity"
    volumes:
      - .:/workspace

  jupyter:
    platform: linux/amd64
    build:
      context: .
      dockerfile: jupyter.Dockerfile
    volumes:
      - ./notebooks:/var/task/notebooks
      - ./packages:/var/task/packages
      - ./start-juptyer.sh:/var/task/start-juptyer.sh
    env_file:
      - .env
    ports:
      - "8888:8888"
    depends_on:
      - s3mock

  s3mock:
    image: adobe/s3mock
    environment:
      - initialBuckets=notebooks,output
    ports:
      - "9090:9090"
    volumes:
      - ./.s3mock-data:/s3mockroot

  notebook-executor:
    platform: linux/amd64
    build:
      context: .
      dockerfile: lambdas/notebook-executor/notebook-executor.Dockerfile
    # command: "app.lambda_function.lambda_handler"
    ports:
      - "9000:8080"
    volumes:
      - ./notebooks:/var/task/notebooks
      - ./packages:/var/task/packages
      - ./lambdas/notebook-executor/app:/var/task/app
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_S3_BUCKET_NOTEBOOK_OUTPUT: ${AWS_S3_BUCKET_NOTEBOOK_OUTPUT}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_LAMBDA_FUNCTION_MEMORY_SIZE: 1024
      ENVIRONMENT: ${ENVIRONMENT}
      DD_LAMBDA_HANDLER: app.lambda_function.lambda_handler
      DD_SITE: ${DD_SITE}
      DD_API_KEY: ${DD_API_KEY}
      DD_TRACE_ENABLED: true
      DD_SERVICE: notebook-executor
      DD_ENV: ${ENVIRONMENT}
      DD_VERSION: 0.0.1
      DD_TRACE_DEBUG: false
      DD_APM_ENABLED: true
    labels:
      com.datadoghq.ad.logs: '[{"source": "docker-compose", "service": "notebook-executor"}]'
      com.datadoghq.tags.env: development
      com.datadoghq.tags.service: notebook-executor

