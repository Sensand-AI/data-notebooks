version: '3.8'

services:
  jupyter:
    build:
      context: .
      dockerfile: jupyter.Dockerfile
    volumes:
      - .:/workspaces/data-notebooks
    command: /bin/bash -c "/workspaces/data-notebooks/startup.sh"
    ports:
      - "8888:8888"
      - "5001:5000"
    env_file:
      - .env
    depends_on:
      - s3mock

  s3mock:
    image: adobe/s3mock
    environment:
      - initialBuckets=notebooks,output
    ports:
      - "9090:9090"
    volumes:
      - ./.s3mock-data:/s3mockroot

  notebook-executor:
    platform: linux/amd64
    build:
      context: lambdas/notebook-executor
      dockerfile: Dockerfile
    ports:
      - "9000:8080"
    volumes:
      - ./notebooks:/var/task/notebooks  # Mount the host's 'notebooks' directory to '/var/task/notebooks' in the container
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: us-east-1
      AWS_LAMBDA_FUNCTION_MEMORY_SIZE: 1024

  datadog-agent:
    cgroup: host
    image: datadog/agent:7
    environment:
      DD_API_KEY: ${DD_API_KEY}
      DD_APM_ENABLED: ${DD_APM_ENABLED}
      DD_SITE: ${DD_SITE}
      DD_APM_NON_LOCAL_TRAFFIC: true
      DD_LOGS_ENABLED: true
      DD_LOGS_CONFIG_DOCKER_CONTAINER_USE_FILE: true
    ports:
      - "8126:8126"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc/:/host/proc/:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /opt/datadog-agent/run:/opt/datadog-agent/run:rw