version: '3.8'

services:

  devcontainer:
    build:
      context: .
      dockerfile: devcontainer.Dockerfile
    command: /bin/sh -c "sleep infinity"
    volumes:
      - .:/workspace

  jupyter:
    platform: linux/amd64
    build:
      context: .
      dockerfile: jupyter.Dockerfile
    volumes:
      - ./notebooks:/var/task/notebooks
      - ./packages:/var/task/packages
      - ./start-juptyer.sh:/var/task/start-juptyer.sh
    env_file:
      - .env
    ports:
      - "8888:8888"
    depends_on:
      - s3mock

  s3mock:
    image: adobe/s3mock
    environment:
      - initialBuckets=notebooks,output
    ports:
      - "9090:9090"
    volumes:
      - ./.s3mock-data:/s3mockroot

  notebook-executor:
    platform: linux/amd64
    build:
      context: .
      dockerfile: lambdas/notebook-executor/notebook-executor.Dockerfile
    ports:
      - "9000:8080"
    volumes:
      - ./notebooks:/var/task/notebooks
      - ./packages:/var/task/packages
      - ./lambdas/notebook-executor/app:/var/task/app
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_S3_BUCKET_NOTEBOOK_OUTPUT: ${AWS_S3_BUCKET_NOTEBOOK_OUTPUT}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
      AWS_LAMBDA_FUNCTION_MEMORY_SIZE: 1024
      DATADOG_HOST: datadog-agent
      ENVIRONMENT: ${ENVIRONMENT}
      AWS_LAMBDA_FUNCTION_NAME: ${AWS_LAMBDA_FUNCTION_NAME}
    labels:
      com.datadoghq.ad.logs: '[{"source": "docker-compose"}]'
      com.datadoghq.tags.env: development
      com.datadoghq.tags.service: ${AWS_LAMBDA_FUNCTION_NAME}}

