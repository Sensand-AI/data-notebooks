{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from gis_utils.dataframe import get_bbox_from_geodf\n",
    "from aws_utils import S3Utils\n",
    "import calendar\n",
    "import time\n",
    "from gis_utils.meteo import OpenMeteoAPI\n",
    "\n",
    "# Configure logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days_between(date_str1: str, date_str2: str, format = \"%Y-%m-%d\") -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of days between two dates given as strings.\n",
    "\n",
    "    Parameters:\n",
    "    - date_str1 (str): The first date string.\n",
    "    - date_str2 (str): The second date string.\n",
    "\n",
    "    Returns:\n",
    "    - int: The difference in days between the two dates.\n",
    "    \n",
    "    Example:\n",
    "    ```python\n",
    "    days_difference = calculate_days_between('2024-05-01', '2024-04-25')\n",
    "    print(f\"The difference in days is: {days_difference}\")\n",
    "        \n",
    "    \"\"\"\n",
    "    # convert the date strings into datetime objects\n",
    "    date_format = format  # allow for custom date formats because merica\n",
    "    datetime1 = datetime.strptime(date_str1, date_format)\n",
    "    datetime2 = datetime.strptime(date_str2, date_format)\n",
    "    \n",
    "    # calculate the difference in days\n",
    "    delta = datetime1 - datetime2\n",
    "    return abs(delta.days)  # use abs to ensure a non-negative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=parameters\n",
    "\n",
    "model = \"weather\"\n",
    "#years = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "years = [2024]\n",
    "#months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "months = [\"January\", \"February\", \"March\", \"April\"]\n",
    "propertyName = \"test\"\n",
    "output_type = \"weather\"\n",
    "datetime_from=\"2023-12-01\"\n",
    "datetime_end=\"2023-12-31\"\n",
    "boundaryName = \"boundaryName\"\n",
    "timezone = \"Australia/Sydney\"\n",
    "historical = True\n",
    "\n",
    "workspaceId = \"018f9876-b3d7-73aa-97e6-0cf7a874383d\"\n",
    "propertyId = \"018f99ea-564e-72fa-a4b7-2dbd24b65c3e\"\n",
    "local=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_data(weather_data, variable_order):\n",
    "    variables = {name: weather_data.Variables(index).ValuesAsNumpy() for index, name in enumerate(variable_order)}\n",
    "    time_range = pd.date_range(\n",
    "        start=pd.to_datetime(weather_data.Time(), unit=\"s\", utc=True),\n",
    "        end=pd.to_datetime(weather_data.TimeEnd(), unit=\"s\", utc=True),\n",
    "        freq=pd.Timedelta(seconds=weather_data.Interval()),\n",
    "        inclusive=\"left\"\n",
    "    )\n",
    "    data = {\"date\": time_range}\n",
    "    data.update(variables)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def map_months_to_numbers(months):\n",
    "    \"\"\"\n",
    "    Map month names to their corresponding calendar numbers using the calendar module.\n",
    "    \"\"\"\n",
    "    # Using calendar.month_abbr which is case-sensitive, ensure input is properly formatted\n",
    "    month_to_number = {calendar.month_name[i].lower(): i for i in range(1, 13)}\n",
    "    return {month.lower(): month_to_number[month.lower()] for month in months}\n",
    "\n",
    "def get_month_date_range(year, month, month_numbers):\n",
    "    \"\"\"\n",
    "    Generate the start (from) and end (to) date strings for a given month and year,\n",
    "    using the month numbers dictionary provided.\n",
    "    \"\"\"\n",
    "    month_number = month_numbers[month.lower()]  # Access using lowercase to avoid case sensitivity issues\n",
    "    first_day = 1\n",
    "    last_day = calendar.monthrange(year, month_number)[1]  # Get the last day of the month\n",
    "    datetime_from = f\"{year}-{month_number:02d}-{first_day:02d}\"\n",
    "    datetime_end = f\"{year}-{month_number:02d}-{last_day:02d}\"\n",
    "    return datetime_from, datetime_end\n",
    "\n",
    "def get_date_ranges(years, months):\n",
    "    \"\"\"\n",
    "    Compute date ranges for each month in each given year.\n",
    "    \"\"\"\n",
    "    month_numbers = map_months_to_numbers(months)\n",
    "    date_ranges = {}\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            datetime_from, datetime_end = get_month_date_range(year, month, month_numbers)\n",
    "            date_ranges[f\"{year} {month}\"] = (datetime_from, datetime_end)\n",
    "    return date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly = [\n",
    "\t\t\"temperature_2m\",\n",
    "\t\t\"relative_humidity_2m\",\n",
    "\t\t\"dew_point_2m\",\n",
    "\t\t\"precipitation\",\n",
    "\t\t\"weather_code\",\n",
    "\t\t\"cloud_cover\",\n",
    "\t\t\"et0_fao_evapotranspiration\",\n",
    "\t\t\"wind_speed_10m\",\n",
    "\t\t\"wind_speed_40m\"\n",
    "]\n",
    "daily = [\n",
    "\t\t\"weather_code\", \n",
    "\t\t\"temperature_2m_max\", \n",
    "\t\t\"temperature_2m_min\",\n",
    "\t\t\"apparent_temperature_max\", \n",
    "\t\t\"apparent_temperature_min\",\n",
    "\t\t\"sunrise\",\n",
    "\t\t\"sunset\",\n",
    "\t\t\"daylight_duration\",\n",
    "\t\t\"sunshine_duration\",\n",
    "\t\t\"uv_index_max\",\n",
    "\t\t\"uv_index_clear_sky_max\",\n",
    "\t\t\"precipitation_sum\",\n",
    "\t\t\"precipitation_hours\",\n",
    "\t\t\"wind_direction_10m_dominant\",\n",
    "\t\t\"shortwave_radiation_sum\",\n",
    "\t\t\"et0_fao_evapotranspiration\"\n",
    "]\n",
    "\n",
    "forecast_hourly = [\n",
    "\t\t\"temperature_2m\",\n",
    "    \"apparent_temperature\", # added as apparent temp included in daily forecast\n",
    "\t\t\"relative_humidity_2m\",\n",
    "\t\t\"dew_point_2m\",\n",
    "\t\t\"precipitation\",\n",
    "\t\t\"weather_code\",\n",
    "\t\t\"cloud_cover\",\n",
    "\t\t\"et0_fao_evapotranspiration\",\n",
    "\t\t\"wind_speed_10m\",\n",
    "    \"wind_speed_40m\",\n",
    "    \"wind_direction_10m\",\n",
    "\t\t\"wind_direction_40m\", # Do we need to fetch data at 10m and 40m above ground?\n",
    "\t\t\"wind_gusts_10m\",\n",
    "\t\t\"sunshine_duration\", # seconds of sunshine in preceeding hour\n",
    "\t\t\"visibility\",\n",
    "\t\t\"soil_temperature_0_to_10cm\",\n",
    "\t\t\"soil_moisture_0_to_10cm\"\n",
    "]\n",
    "\n",
    "forecast_daily = [\n",
    "\t\t\"weather_code\",\n",
    "\t\t\"temperature_2m_max\", \n",
    "\t\t\"temperature_2m_min\",\n",
    "\t\t\"apparent_temperature_max\", \n",
    "\t\t\"apparent_temperature_min\",\n",
    "\t\t\"sunrise\",\n",
    "\t\t\"sunset\",\n",
    "\t\t\"uv_index_max\",\n",
    "\t\t\"daylight_duration\",\n",
    "\t\t\"sunshine_duration\", # removed uv from forecast as BOM doesn't include it?\n",
    "\t\t\"precipitation_sum\",\n",
    "\t\t\"precipitation_hours\",\n",
    "\t\t\"wind_speed_10m_max\", # added for completeness\n",
    "\t\t\"wind_gusts_10m_max\", # added for completeness\n",
    "\t\t\"wind_direction_10m_dominant\",\n",
    "\t\t\"shortwave_radiation_sum\",\n",
    "\t\t\"et0_fao_evapotranspiration\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_bounding_box\n",
    "\n",
    "api = OpenMeteoAPI()\n",
    "\n",
    "def process_date_range(date_range, dates, storage_directory, notebook_key, gpd_lat, gpd_lon, boundary_id):\n",
    "    print(f\"For {date_range}: Start Date = {dates[0]}, End Date = {dates[1]}\")\n",
    "    calculated_date_from = dates[0]\n",
    "    calculated_date_end = dates[1]\n",
    "    \n",
    "    # Ensure the specific output directory for this date range exists\n",
    "    year, month = date_range.split(\" \")\n",
    "    output_directory = os.path.join(storage_directory, notebook_key, year, month)\n",
    "\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # Define the filenames for daily and hourly weather data outputs\n",
    "    weather_output_daily_filename = os.path.join(output_directory, f\"{model}_{propertyName}_{calculated_date_from}_{calculated_date_end}_daily_weather.csv\")\n",
    "    weather_output_hourly_filename = os.path.join(output_directory, f\"{model}_{propertyName}_{calculated_date_from}_{calculated_date_end}_hourly_weather.csv\")\n",
    "\n",
    "    responses = api.fetch_weather_data(\n",
    "        latitude=gpd_lat,\n",
    "        longitude=gpd_lon,\n",
    "        start_date=calculated_date_from,\n",
    "        end_date=calculated_date_end,\n",
    "        historical=True,\n",
    "        daily=daily,\n",
    "        hourly=hourly,\n",
    "        timezone=timezone\n",
    "    )\n",
    "    response = responses[0]\n",
    "\n",
    "    hourly_dataframe = process_weather_data(response.Hourly(), hourly)\n",
    "    daily_dataframe = process_weather_data(response.Daily(), daily)\n",
    "\n",
    "    hourly_dataframe[\"longitude\"] = gpd_lon\n",
    "    hourly_dataframe[\"latitude\"] = gpd_lat\n",
    "    hourly_dataframe[\"boundary_id\"] = boundary_id\n",
    "    hourly_dataframe[\"boundary_name\"] = notebook_key\n",
    "    hourly_dataframe[\"workspace_id\"] = workspaceId\n",
    "    hourly_dataframe[\"property_id\"] = propertyId\n",
    "\n",
    "    daily_dataframe[\"longitude\"] = gpd_lon\n",
    "    daily_dataframe[\"latitude\"] = gpd_lat\n",
    "    daily_dataframe[\"boundary_id\"] = boundary_id\n",
    "    daily_dataframe[\"boundary_name\"] = notebook_key\n",
    "    daily_dataframe[\"workspace_id\"] = workspaceId\n",
    "    daily_dataframe[\"property_id\"] = propertyId\n",
    "\n",
    "    # Save the dataframes to CSV\n",
    "    daily_dataframe.to_csv(weather_output_daily_filename, index=False)\n",
    "    hourly_dataframe.to_csv(weather_output_hourly_filename, index=False)\n",
    "\n",
    "    time.sleep(1.5)  # Pause between API requests\n",
    "\n",
    "def process_date_range_forecast(storage_directory, notebook_key, gpd_lat, gpd_lon, boundary_id):\n",
    "    forecast_days = 7 # API docs indicate 7 days is the max forecast period\n",
    "\n",
    "    # dynamically generate start/end dates based on current date and forecast_days\n",
    "    datetime_from = (datetime.now().date()).strftime(\"%Y-%m-%d\")\n",
    "    datetime_end = (datetime.now().date() + pd.Timedelta(days=forecast_days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    date_ranges = pd.date_range(start=datetime_from, end=datetime_end, freq='D')\n",
    "\n",
    "    calculated_date_from = date_ranges[0].strftime(\"%Y-%m-%d\")\n",
    "    calculated_date_end = date_ranges[-1].strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    print(f\"start date: {calculated_date_from}\")\n",
    "    print(f\"start date: {calculated_date_end}\")\n",
    "\n",
    "    output_directory = f\"{storage_directory}/{notebook_key}/forecast/{date_ranges[0].strftime('%Y-%m-%d')}\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    weather_output_forecast_daily_filename = os.path.join(output_directory, f\"{model}_{propertyName}_daily_weather.csv\")\n",
    "    weather_output_forecast_hourly_filename = os.path.join(output_directory, f\"{model}_{propertyName}_hourly_weather.csv\")\n",
    "\n",
    "    responses = api.fetch_weather_data(\n",
    "        latitude=gpd_lat,\n",
    "        longitude=gpd_lon,\n",
    "        start_date=calculated_date_from,\n",
    "        end_date=calculated_date_end,\n",
    "        historical=False,\n",
    "        daily=forecast_daily,\n",
    "        hourly=forecast_hourly,\n",
    "        timezone=timezone\n",
    "    )\n",
    "    response = responses[0]\n",
    "\n",
    "    forecast_hourly_dataframe = process_weather_data(response.Hourly(), forecast_hourly)\n",
    "    forecast_daily_dataframe = process_weather_data(response.Daily(), forecast_daily)\n",
    "\n",
    "    forecast_hourly_dataframe[\"longitude\"] = gpd_lon\n",
    "    forecast_hourly_dataframe[\"latitude\"] = gpd_lat\n",
    "    forecast_hourly_dataframe[\"boundary_id\"] = boundary_id\n",
    "    forecast_hourly_dataframe[\"boundary_name\"] = notebook_key\n",
    "    forecast_hourly_dataframe[\"workspace_id\"] = workspaceId\n",
    "    forecast_hourly_dataframe[\"property_id\"] = propertyId\n",
    "\n",
    "    forecast_daily_dataframe[\"longitude\"] = gpd_lon\n",
    "    forecast_daily_dataframe[\"latitude\"] = gpd_lat\n",
    "    forecast_daily_dataframe[\"boundary_id\"] = boundary_id\n",
    "    forecast_daily_dataframe[\"boundary_name\"] = notebook_key\n",
    "    forecast_daily_dataframe[\"workspace_id\"] = workspaceId\n",
    "    forecast_daily_dataframe[\"property_id\"] = propertyId\n",
    "\n",
    "    print(weather_output_forecast_daily_filename)\n",
    "    forecast_daily_dataframe.to_csv(weather_output_forecast_daily_filename, index=False)\n",
    "    forecast_hourly_dataframe.to_csv(weather_output_forecast_hourly_filename, index=False)\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_file_io\n",
    "\n",
    "# req = geojson\n",
    "# geojson_data = req['body']  # Directly accessing the 'body' since it's already a dictionary in this mock setup\n",
    "\n",
    "# # Convert the GeoJSON string to a GeoDataFrame\n",
    "# gdf = gpd.read_file(StringIO(json.dumps(geojson_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in environment variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boundary ID: 018f9f82-ea97-749d-baea-cd65d3ecc989\n",
      "Centroid: [145.63004997472387, -38.40358558670786]\n",
      "start date: 2024-05-28\n",
      "start date: 2024-06-04\n"
     ]
    },
    {
     "ename": "OpenMeteoRequestsError",
     "evalue": "{'reason': \"Data corrupted at path ''. Cannot initialize ForecastVariableDaily from invalid String value weather_codetemperature_2m_max.\", 'error': True}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 52\u001b[0m\n\u001b[1;32m     38\u001b[0m notebook_key \u001b[38;5;241m=\u001b[39m geojson_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Iterate over each date range calculated previously\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Using the function within another iterator:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# for date_range, dates in date_ranges.items():\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#         boundary_id\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mprocess_date_range_forecast\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnotebook_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpd_lat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpd_lon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboundary_id\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 76\u001b[0m, in \u001b[0;36mprocess_date_range_forecast\u001b[0;34m(storage_directory, notebook_key, gpd_lat, gpd_lon, boundary_id)\u001b[0m\n\u001b[1;32m     73\u001b[0m weather_output_forecast_daily_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpropertyName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_daily_weather.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m weather_output_forecast_hourly_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpropertyName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hourly_weather.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m responses \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_weather_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpd_lat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpd_lon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculated_date_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcalculated_date_end\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdaily\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_daily\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhourly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_hourly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimezone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimezone\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m response \u001b[38;5;241m=\u001b[39m responses[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     88\u001b[0m forecast_hourly_dataframe \u001b[38;5;241m=\u001b[39m process_weather_data(response\u001b[38;5;241m.\u001b[39mHourly(), forecast_hourly)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/gis_utils/meteo.py:50\u001b[0m, in \u001b[0;36mOpenMeteoAPI.fetch_weather_data\u001b[0;34m(self, latitude, longitude, start_date, end_date, daily, hourly, timezone, historical)\u001b[0m\n\u001b[1;32m     39\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: latitude,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m: longitude,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone\u001b[39m\u001b[38;5;124m\"\u001b[39m: timezone,\n\u001b[1;32m     47\u001b[0m }\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Make the API request using the configured client\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweather_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openmeteo_requests/Client.py:47\u001b[0m, in \u001b[0;36mClient.weather_api\u001b[0;34m(self, url, params, method)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweather_api\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, params: \u001b[38;5;28many\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[WeatherApiResponse]:\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get and decode as weather api\"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWeatherApiResponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/openmeteo_requests/Client.py:30\u001b[0m, in \u001b[0;36mClient._get\u001b[0;34m(self, cls, url, params, method)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m429\u001b[39m]:\n\u001b[1;32m     29\u001b[0m     response_body \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenMeteoRequestsError(response_body)\n\u001b[1;32m     32\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     34\u001b[0m data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mOpenMeteoRequestsError\u001b[0m: {'reason': \"Data corrupted at path ''. Cannot initialize ForecastVariableDaily from invalid String value weather_codetemperature_2m_max.\", 'error': True}"
     ]
    }
   ],
   "source": [
    "#papermill_description=process_variables\n",
    "\n",
    "# Set up the initial directory based on the environment\n",
    "storage_directory = \"/tmp\"\n",
    "if local:\n",
    "    storage_directory = \"/workspace/notebook_outputs\"\n",
    "\n",
    "# Ensure the storage directory exists\n",
    "os.makedirs(storage_directory, exist_ok=True)\n",
    "\n",
    "workspace_directory = f\"/workspace/geojsons\"\n",
    "\n",
    "date_ranges = get_date_ranges(years, months)\n",
    "\n",
    "# Iterate over each geojson file in workspace directory\n",
    "for geojson_file in os.listdir(workspace_directory):\n",
    "    # Read the geojson file\n",
    "    with open(os.path.join(workspace_directory, geojson_file), \"r\") as file:\n",
    "   \n",
    "        geojson_data = json.load(file)\n",
    "\n",
    "        # Convert the GeoJSON string to a GeoDataFrame\n",
    "        gdf = gpd.read_file(StringIO(json.dumps(geojson_data)))\n",
    "\n",
    "        # Get bounding box from GeoJSON\n",
    "        bbox = get_bbox_from_geodf(geojson_data)\n",
    "\n",
    "        boundary_id = gdf['boundaryId'][0]\n",
    "\n",
    "        print(f\"Boundary ID: {boundary_id}\")\n",
    "\n",
    "        # get the central latitude and longitude of the bounding box\n",
    "        gpd_lon = (bbox[0] + bbox[2]) / 2\n",
    "        gpd_lat = (bbox[1] + bbox[3]) / 2\n",
    "        centroid = [gpd_lon, gpd_lat]\n",
    "        print(f\"Centroid: {centroid}\")\n",
    "\n",
    "        notebook_key = geojson_data['name']\n",
    "\n",
    "        # Iterate over each date range calculated previously\n",
    "        # Using the function within another iterator:\n",
    "        # for date_range, dates in date_ranges.items():\n",
    "        #     process_date_range(\n",
    "        #         date_range, \n",
    "        #         dates,\n",
    "        #         storage_directory, \n",
    "        #         notebook_key,\n",
    "        #         gpd_lat, \n",
    "        #         gpd_lon, \n",
    "        #         boundary_id\n",
    "        #     )\n",
    "        process_date_range_forecast(\n",
    "            storage_directory, \n",
    "            notebook_key,\n",
    "            gpd_lat, \n",
    "            gpd_lon, \n",
    "            boundary_id\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aws_s3_notebook_output = os.getenv('AWS_S3_BUCKET_NOTEBOOK_OUTPUT')\n",
    "# aws_default_region = os.getenv('AWS_DEFAULT_REGION')\n",
    "# s3_client = S3Utils(\n",
    "# \t\tregion_name=aws_default_region,\n",
    "# \t\ts3_bucket=aws_s3_notebook_output,\n",
    "# \t\tprefix=notebook_key\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes to CSV\n",
    "# output_dir = f\"{storage_directory}/{notebook_key}/{calculated_date_from}_{calculated_date_end}\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# daily_dataframe.to_csv(weather_output_daily_filename, index=False)\n",
    "# hourly_dataframe.to_csv(weather_output_hourly_filename, index=False)\n",
    "\n",
    "\n",
    "# s3_client.upload_file(\n",
    "# \t\tfile_path=weather_output_daily_filename,\n",
    "# )\n",
    "\n",
    "# s3_client.upload_file(\n",
    "# \t\tfile_path=weather_output_hourly_filename,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
