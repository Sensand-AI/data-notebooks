{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the chosen geotiffs before passing to the stratification notebook\n",
    "\n",
    "Checklist:\n",
    "- all incoming data using same projection (and if not, reproject)\n",
    "- align the spatial resolutions\n",
    "- data cleaning - check for missing values\n",
    "- normalise/ scale pixel values\n",
    "- create data cube\n",
    "\n",
    "some resources to check later:\n",
    "https://discourse.pangeo.io/t/advice-for-scalable-raster-vector-extraction/4129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from rasterio.enums import Resampling\n",
    "import rioxarray\n",
    "import rio_cogeo\n",
    "\n",
    "from pydantic import BaseModel, field_validator\n",
    "from typing import List\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[\n",
    "                        logging.FileHandler(\"debug.log\"),\n",
    "                        logging.StreamHandler()\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResamplingMethods:\n",
    "    NEAREST = \"nearest\"\n",
    "    BILINEAR = \"bilinear\"\n",
    "    CUBIC = \"cubic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rasters(raster_dir):\n",
    "    data_arrays = []\n",
    "    for raster_file in os.listdir(raster_dir):\n",
    "        if raster_file.endswith('.tiff') or raster_file.endswith('.tif'):\n",
    "            raster_path = os.path.join(raster_dir, raster_file)\n",
    "            # Open the raster file as an xarray DataArray with rioxarray\n",
    "            data_array = rioxarray.open_rasterio(raster_path)\n",
    "            data_arrays.append(data_array)\n",
    "    return data_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This function assumes all incoming rasters only have one band. If multi-band rasters are included, it will need to be modified.\n",
    "\n",
    "def projection_check(data_arrays, target_crs):\n",
    "    reprojected_data_arrays = []\n",
    "    for da in data_arrays:\n",
    "        if da.rio.crs != target_crs:\n",
    "            # Reproject the data array to the target CRS\n",
    "            reprojected_da = da.rio.reproject(target_crs)\n",
    "            reprojected_data_arrays.append(reprojected_da)\n",
    "        else:\n",
    "            reprojected_data_arrays.append(da)\n",
    "    return reprojected_data_arrays\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtypes(data_arrays):\n",
    "    converted_data_arrays = []\n",
    "    for da in data_arrays:\n",
    "        if da.dtype == \"uint16\":\n",
    "            # Assume the original NoData value is known, set it as such or detect it\n",
    "            original_nodata = da.rio.nodata\n",
    "            input_raster = da.astype(\"float32\")\n",
    "            # Replace original NoData with NaN in float32\n",
    "            if original_nodata is not None:\n",
    "                input_raster = input_raster.where(\n",
    "                    input_raster != original_nodata, np.nan\n",
    "                )\n",
    "            \n",
    "        input_raster.rio.write_nodata(np.nan, inplace=True)\n",
    "        converted_data_arrays.append(input_raster)\n",
    "    return converted_data_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistency(data_arrays, dst_crs):\n",
    "    formatted_crs = f\"EPSG:{dst_crs}\"\n",
    "    # Check for inconsistent data types\n",
    "    dtypes = [da.dtype for da in data_arrays]\n",
    "    unique_dtypes = set(dtypes)\n",
    "    if len(unique_dtypes) > 1:\n",
    "        logging.error(\"Inconsistent data types found: {}\".format(unique_dtypes))\n",
    "    else:\n",
    "        logging.info(\"All data arrays have consistent data types.\")\n",
    "\n",
    "    # Convert from uint16 to float32 if needed:\n",
    "    if \"uint16\" in unique_dtypes:\n",
    "        logging.info(\"Converting uint16 data arrays to float32.\")\n",
    "        data_arrays = convert_dtypes(data_arrays)\n",
    "    else:\n",
    "        logging.info(\"No uint16 data arrays found.\")\n",
    "\n",
    "    # Check for inconsistent CRS\n",
    "    crs_set = {da.rio.crs for da in data_arrays if da.rio.crs is not None}\n",
    "    if len(crs_set) > 1:\n",
    "        logging.error(\"Inconsistent CRS found: {}\".format(crs_set))\n",
    "        logging.info(\"Attempting to convert all data arrays to the same data type.\")\n",
    "        return projection_check(data_arrays, formatted_crs)\n",
    "    else:\n",
    "        logging.info(\"All data arrays have a consistent CRS.\")\n",
    "\n",
    "    if crs_set != {formatted_crs}:\n",
    "        logging.info(\"Converting all data arrays to the target CRS.\")\n",
    "        return projection_check(data_arrays, formatted_crs)\n",
    "\n",
    "    # Check for missing values in any of the DataArrays\n",
    "    missing_values_found = False\n",
    "    for da in data_arrays:\n",
    "        if da.isnull().any():\n",
    "            logging.error(\"Missing values found in one of the DataArrays.\")\n",
    "            missing_values_found = True\n",
    "            break\n",
    "    if not missing_values_found:\n",
    "        logging.info(\"No missing values found in any of the data arrays.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_finest_resolution(data_arrays) -> float:\n",
    "    finest_x_res = float('inf')  # Start with a large number as the finest resolution\n",
    "    finest_y_res = float('inf')\n",
    "\n",
    "    for da in data_arrays:\n",
    "            current_x_res = abs(da.rio.resolution()[0])\n",
    "            current_y_res = abs(da.rio.resolution()[1])\n",
    "            # Update the finest resolution if the current one is smaller\n",
    "            if current_x_res < finest_x_res and current_y_res < finest_y_res:\n",
    "                finest_width = current_x_res\n",
    "                finest_height = current_y_res\n",
    "    return finest_x_res, finest_y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_rasters_to_finest_pixel(data_arrays):\n",
    "    finest_x_res, finest_y_res = find_finest_resolution(data_arrays) #find the smallest pixels in the input arrays to then match the rest to\n",
    "\n",
    "    print(f\"finest res: {finest_x_res}, {finest_y_res}\")\n",
    "    resampled_data_arrays = []\n",
    "\n",
    "    for da in data_arrays:\n",
    "\n",
    "        current_x_res = abs(da.rio.resolution()[0])\n",
    "        current_y_res = abs(da.rio.resolution()[1])\n",
    "\n",
    "\n",
    "        scale_factor_x = current_x_res / finest_x_res\n",
    "        scale_factor_y = current_y_res / finest_y_res \n",
    "\n",
    "        print(f\"scale_factor_x: {scale_factor_x}\")\n",
    "        print(f\"scale_factor_y: {scale_factor_y}\")\n",
    "\n",
    "        new_width = int(da.rio.width / scale_factor_x)\n",
    "        new_height = int(da.rio.height / scale_factor_y)\n",
    "\n",
    "        print(f\"Resampled width pixels: {new_width}\")\n",
    "        print(f\"Resampled height pixels: {new_height}\")\n",
    "        \n",
    "        resampled_da = da.rio.reproject(\n",
    "            da.rio.crs, \n",
    "            shape=(new_height, new_width),\n",
    "            resampling = Resampling.bilinear)\n",
    "        resampled_data_arrays.append(resampled_da)\n",
    "\n",
    "    return resampled_data_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crs = 3857\n",
    "\n",
    "input_raster_dir = \"/workspace/notebooks/sandbox/data/stratification/input-rasters\"\n",
    "output_raster_dir = \"/workspace/notebooks/sandbox/data/stratification/processed-rasters\"\n",
    "\n",
    "input_rasters = load_rasters(input_raster_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 03:06:54,502 - INFO - All data arrays have consistent data types.\n",
      "2024-06-24 03:06:54,505 - INFO - No uint16 data arrays found.\n",
      "2024-06-24 03:06:54,507 - INFO - All data arrays have a consistent CRS.\n",
      "2024-06-24 03:06:54,509 - INFO - Converting all data arrays to the target CRS.\n"
     ]
    }
   ],
   "source": [
    "# check that the loaded rasters have the same CRS and dtype and there are no missing data:\n",
    "\n",
    "checked_rasters = check_consistency(input_rasters, target_crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Resampling Method\n",
    "\n",
    "- Nearest Neighbor: Fast and suitable for categorical data.\n",
    "- Bilinear: Good for continuous data where interpolation between values can be meaningful.\n",
    "- Cubic: Better for continuous data where a smoother output is desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finest res: inf, inf\n",
      "scale_factor_x: 0.0\n",
      "scale_factor_y: 0.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resampled_data_arrays \u001b[38;5;241m=\u001b[39m \u001b[43mresample_rasters_to_finest_pixel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchecked_rasters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 19\u001b[0m, in \u001b[0;36mresample_rasters_to_finest_pixel\u001b[0;34m(data_arrays)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_factor_x: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_factor_x\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_factor_y: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscale_factor_y\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m new_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale_factor_x\u001b[49m)\n\u001b[1;32m     20\u001b[0m new_height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(da\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m/\u001b[39m scale_factor_y)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResampled width pixels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_width\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "resampled_data_arrays = resample_rasters_to_finest_pixel(checked_rasters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in resampled_data_arrays:\n",
    "    print(da.rio.resolution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for da in checked_rasters:\n",
    "    print(da.rio.shape)\n",
    "for da in resampled_data_arrays:\n",
    "    print(da.rio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
