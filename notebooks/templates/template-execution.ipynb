{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production/execution template jupyter notebook\n",
    "\n",
    "This notebook is a generic template for the data notebooks repository. It is based on a notebook that collects Digital elevation data from an online source (a STAC endpoint hosted by Geoscience Australia). You can use this notebook as a guide for creating your own notebooks.\n",
    "\n",
    "Use this template as a starting point so that as the notebook library grows, there is consistency in formatting as well as the inclusion of required core packages, parameters and tags.\n",
    "PLease refer to the README.md for more information and a more detailed breakdown of ths templates.\n",
    "\n",
    "## Execution templates\n",
    "\n",
    "Executeion (also called production) notebooks have some additional requirements over the exploration notebooks.\n",
    "\n",
    "Execution notebooks must include papermill comments and tags.\n",
    "\n",
    "### Parameter definition and tags\n",
    "\n",
    "For execution notebooks to work, both `papermill comments` and `cell tags` must be included. Each cell in this template has these included. `Papermill comments` are different to regular comments, though the syntax is the same. Take care to not remove the papermill comments when cleaning up a notebook for production.\n",
    "\n",
    "\n",
    "### Parameter cell\n",
    "One cell must be designated `parameters`. This cell must have BOTH the `papermill comment` designating it as the aprameters cell, and the `tag`.\n",
    "\n",
    "Parameters that need to be passed into the notebook must be included in the parameter cell. If the user will be inputting variables in the front end of the platform, for example a date range or a dataset name, you will input these here. \n",
    "\n",
    "Example:\n",
    "\n",
    "#### papermill comment:\n",
    "`papermill_description=parameters`\n",
    "\n",
    "#### Jupyter tags in vscode:\n",
    "- use the 'more actions' button in the top right of a cell to access tags\n",
    "- select `add cell tag`\n",
    "- make cell tag `parameters`\n",
    "\n",
    "## Schema.json file\n",
    "When creating a notebook that will be usable in the platform and accessed by users, you will also need to create a `schema.json` file. There are examples of these in the `production/` directory and an example is provided in this directory too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages\n",
    "\n",
    "Unlike the experimental notebooks, you need to make sure all packages used in a production/execution notebook are included in the GIS image. You can add packages to the `requirements.txt` files in this repository, following the guidelines in the README.md.\n",
    "\n",
    "If you are updating the GIS image, you will need to rebuild the image and restart the kernel in this notebook, as well as have access to the ECR repository through aws-vault. \n",
    "\n",
    "If you do not need to add new packages, you can safely proceed to installing the packages in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add a papermill_description to every cell\n",
    "add tags to every cell. \n",
    "Parameters cell MUST have both params tag and papermill description\n",
    "notebook key - for executable notebooks\n",
    "\n",
    "The papaermill things are comments and are called comments, and these are separate to tags.\n",
    "\n",
    "exploratory vs executbale notebook template. Make example of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-py"
    ]
   },
   "outputs": [],
   "source": [
    "#papermill_description=imports\n",
    "\n",
    "# Core packages\n",
    "import json\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "\n",
    "# Geospatial\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import pystac_client\n",
    "from gis_utils.stac import initialize_stac_client, query_stac_api, save_metadata_sidecar, process_dem_asset_and_mask\n",
    "from gis_utils.dataframe import get_bbox_from_geodf\n",
    "import rasterio.plot\n",
    "from rio_cogeo.cogeo import cog_translate\n",
    "from rio_cogeo.profiles import cog_profiles\n",
    "from rasterio.io import MemoryFile\n",
    "from rasterio.warp import calculate_default_transform\n",
    "\n",
    "\n",
    "# this is a GDAL flag, it does not impact AWS access.  Used for accessing public buckets, which we do for some AWS earth data repositories\n",
    "\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "It is good practice to keep your functions at the top of the notebook so you can easily find them. Please include documentation for your functions in a notebook being used in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-py"
    ]
   },
   "outputs": [],
   "source": [
    "#papermill_description=get_coords_from_geodataframe\n",
    "\n",
    "def get_coords_from_geodataframe(gdf):\n",
    "    \"\"\"Function to parse features from GeoDataFrame in such a manner that rasterio wants them\"\"\"\n",
    "    import json\n",
    "    return [json.loads(gdf.to_json())['features'][0]['geometry']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "#papermill_description=compute_elevation_statistics\n",
    "\n",
    "def compute_elevation_statistics(dem_data):\n",
    "    \"\"\"\n",
    "    Compute basic elevation statistics from a digital elevation model (DEM) dataset.\n",
    "\n",
    "    This function calculates the minimum, maximum, mean, and standard deviation of elevation\n",
    "    values within the provided DEM data array. It handles the DEM data as a NumPy array,\n",
    "    which is a common format for raster data in Python.\n",
    "\n",
    "    Parameters:\n",
    "    - dem_data (numpy.ndarray): A 2D NumPy array containing elevation data from a DEM raster.\n",
    "      The array should contain numeric values representing elevation at each cell. No-data\n",
    "      values should be represented by NaNs in the array to be properly ignored in calculations.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing the computed elevation statistics, with keys 'min_elevation',\n",
    "      'max_elevation', 'mean_elevation', and 'std_dev_elevation'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the minimum elevation, ignoring any NaN values which represent no-data cells\n",
    "    min_elevation = float(np.nanmin(dem_data))\n",
    "\n",
    "    # Compute the maximum elevation, ignoring any NaN values\n",
    "    max_elevation = float(np.nanmax(dem_data))\n",
    "\n",
    "    # Compute the mean elevation, ignoring any NaN values\n",
    "    mean_elevation = float(np.nanmean(dem_data))\n",
    "\n",
    "    # Compute the standard deviation of elevation, ignoring any NaN values\n",
    "    std_dev_elevation = float(np.nanstd(dem_data))\n",
    "\n",
    "    # Construct and return a dictionary containing the computed statistics\n",
    "    stats = {\n",
    "        'min_elevation': min_elevation,\n",
    "        'max_elevation': max_elevation,\n",
    "        'mean_elevation': mean_elevation,\n",
    "        'std_dev_elevation': std_dev_elevation\n",
    "    }\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter cell\n",
    "\n",
    "The cell below is the parameter cell that is required for production notebooks. This cell must have BOTH the `papermill comment` designating it as the aprameters cell, and the `tag`. \n",
    "\n",
    "You will include default values for parameters, and these will be replaced by values provided via the front end of the platform when the notebook is executed. This example includes an area of interest defined as a geojson polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "#papermill_description=parameters\n",
    "\n",
    "notebook_key = \"localjupyter\"\n",
    "geojson = {\n",
    "    'body': {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"name\": \"dissolved-boundaries\",\n",
    "        \"crs\": {\n",
    "            \"type\": \"name\",\n",
    "            \"properties\": {\n",
    "                \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" \n",
    "            }\n",
    "        },\n",
    "        \"features\": [\n",
    "            {\n",
    "                \"type\": \"Feature\",\n",
    "                \"properties\": {\n",
    "                    \"fid\": 1\n",
    "                },\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Polygon\",\n",
    "                    \"coordinates\": [\n",
    "                        [\n",
    "                            [116.26012130269045, -29.225295369642396],\n",
    "                            [116.261724812149055, -29.241374854584375],\n",
    "                            [116.283751968396274, -29.256813692452539],\n",
    "                            [116.284342735038919, -29.268250184258388],\n",
    "                            [116.292247755352392, -29.265992437426529],\n",
    "                            [116.292360282331941, -29.293057573630019],\n",
    "                            [116.314865678242256, -29.293523728033122],\n",
    "                            [116.326259034921833, -29.293033039128805],\n",
    "                            [116.326315298411629, -29.305397680579894],\n",
    "                            [116.355065941687045, -29.307016748931797],\n",
    "                            [116.355065941687045, -29.306575187382712],\n",
    "                            [116.383366477044206, -29.307384715430175],\n",
    "                            [116.384322956370426, -29.290407813444993],\n",
    "                            [116.387586238777402, -29.282629879611861],\n",
    "                            [116.386517232471661, -29.259807919053017],\n",
    "                            [116.359201308185533, -29.259488866292969],\n",
    "                            [116.359229439930417, -29.259243440415627],\n",
    "                            [116.35242155766754, -29.259292525638209],\n",
    "                            [116.352140240218716, -29.220237788279107],\n",
    "                            [116.302234524787593, -29.223503148505326],\n",
    "                            [116.281388901825679, -29.2239696200396],\n",
    "                            [116.26012130269045, -29.225295369642396]\n",
    "                        ]\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# These parameters must also be in the schema.json. See the template schema file for the example that matches this template notebook.\n",
    "propertyName = \"test\"\n",
    "output_type = \"overlay\"\n",
    "colormap = \"gist_earth\"\n",
    "si_unit = \"metres above sea level\"\n",
    "si_unit_short = \"m\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filename construction and saving files\n",
    "\n",
    "### Geotiff files\n",
    "Geotiff files should have the file extension `.tiff`. Both `.tif` and `.tiff` are valid extensions, but `.tiff` is what we use.\n",
    "\n",
    "We also use additional attribute extensions to denote the intermediary files that will be discarded after the final file is created. It is important that the final file that is going to be uploaded to S3 end with `_cog.public.tiff`. This is because the platform will look for files with this extension to upload to S3.\n",
    "\n",
    "### Saving files to be uploaded to S3\n",
    "\n",
    "When saving files to be uploaded to S3, you must save them in the `/tmp/` directory. This is because the `/tmp/` directory is the only directory that the platform has write access to.\n",
    "\n",
    "If you are testing locally, ths directory won't exist (it's a cloud thing). You can add a boolean flag and alternate between a directory within your workspace and `/tmp/` when testing. An example of how to do this is shown in the `slga.ipynb` production notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'notebook_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#papermill_description=process_variables\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Construct the filenames using propertyName\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# name_property-name_attribute.extension\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m elevation_json_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnotebook_key\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dem_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpropertyName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_elevation-stats.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m output_tiff_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dem_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpropertyName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m output_colored_tiff_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dem_colored_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpropertyName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'notebook_key' is not defined"
     ]
    }
   ],
   "source": [
    "#papermill_description=process_variables\n",
    "\n",
    "# Construct the filenames using propertyName\n",
    "# name_property-name_attribute.extension\n",
    "elevation_json_filename = f\"/tmp/{notebook_key}/dem_{propertyName}_elevation-stats.json\"\n",
    "output_tiff_filename = f\"/tmp/{notebook_key}/dem_{propertyName}.tiff\"\n",
    "\n",
    "output_colored_tiff_filename = f\"/tmp/{notebook_key}/dem_colored_{propertyName}.tiff\"\n",
    "output_cog_filename = f\"/tmp/{notebook_key}/dem_{propertyName}_cog.public.tiff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passing geojson data to the notebook\n",
    "\n",
    "The geojson data is passed to the notebook as a string. This string is then converted to a geojson object in the notebook. This is done to comply with how the platform passes data to the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_file_io\n",
    "\n",
    "req = geojson\n",
    "geojson_data = req['body']\n",
    "\n",
    "# Convert the GeoJSON string to a GeoDataFrame\n",
    "gdf = gpd.read_file(StringIO(json.dumps(geojson_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting additional spatial data\n",
    "\n",
    "This notebook also extracts the centre point of the area of interest and the bounding box (bbox). Becuase polygons can be complicated shapes with many vertices, it is often fater to use the bounding box to extract data from an API. The bounding box is a rectangle that surrounds the polygon. The centre point is the middle of the bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_bounding_box\n",
    "\n",
    "# Get bounding box from GeoJSON\n",
    "bbox = get_bbox_from_geodf(geojson_data)\n",
    "\n",
    "# Get polygon coordinates in rasterio-friendly format\n",
    "coords = get_coords_from_geodataframe(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_stac_init\n",
    "\n",
    "stac_url_dem = \"https://explorer.sandbox.dea.ga.gov.au/stac/\"\n",
    "collections_dem = ['ga_srtm_dem1sv1_0']\n",
    "\n",
    "# Initialize STAC clients\n",
    "print(f\"Initializing STAC client for DEM with URL: {stac_url_dem} and collections: {collections_dem}\")\n",
    "client_dem = initialize_stac_client(stac_url_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_stac_search\n",
    "\n",
    "# Query STAC catalogs\n",
    "items_dem = query_stac_api(client_dem, bbox, collections_dem, None, None) #modified the query_stac_api function to accept polygon + bbox for masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_stac_assets\n",
    "\n",
    "# Only want the dem asset\n",
    "item = items_dem[0]\n",
    "dem_asset = item.assets.get('dem')\n",
    "fallback_dem = {\n",
    "\t\t'title': 'dem',\n",
    "\t\t'href': 'https://dea-public-data.s3-ap-southeast-2.amazonaws.com/projects/elevation/ga_srtm_dem1sv1_0/dem1sv1_0.tif'\n",
    "}\n",
    "primary_dem = dem_asset if dem_asset else fallback_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_dem_asset\n",
    "\n",
    "# Modified function including mask/clip:\n",
    "data, metadata, src = process_dem_asset_and_mask(primary_dem, coords, bbox, output_tiff_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing\n",
    "\n",
    "elevation_stats = compute_elevation_statistics(data)\n",
    "\n",
    "# Serialize 'elevation_stats' to a JSON string\n",
    "elevation_stats_json = json.dumps(elevation_stats)\n",
    "# Convert the JSON string to bytes\n",
    "elevation_stats_bytes = elevation_stats_json.encode()\n",
    "\n",
    "# asset_type signifies the type of asset, e.g. overlay that is stored in the application DB\n",
    "asset_metadata = {\n",
    "    'properties': {\n",
    "        'output_type': output_type,\n",
    "        'si_unit': si_unit,\n",
    "        'si_unit_short': si_unit_short,\n",
    "        'name': 'DEM',\n",
    "    },\n",
    "    'data': {\n",
    "        'elevation_stats': elevation_stats,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=processing_cog\n",
    "\n",
    "with rasterio.open(output_tiff_filename) as mew:\n",
    "    meta = mew.meta.copy()\n",
    "    dst_crs = rasterio.crs.CRS.from_epsg(4326)\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        mew.crs, dst_crs, mew.width, mew.height, *mew.bounds\n",
    "    )\n",
    "\n",
    "    meta.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    tif_data = mew.read(1, masked=True).astype('float32') #setting masked=True here tells rasterio to use masking information if present, but we need to add the mask itself first.\n",
    "    mew_formatted = tif_data.filled(np.nan)\n",
    "\n",
    "    cmap = cm.get_cmap(colormap) #can also use 'terrain' cmap to keep this the same as the preview image from above.\n",
    "    na = mew_formatted[~np.isnan(mew_formatted)]\n",
    "\n",
    "    min_value = min(na)\n",
    "    max_value = max(na)\n",
    "\n",
    "    norm = Normalize(vmin=min_value, vmax=max_value)\n",
    "\n",
    "    coloured_data = (cmap(norm(mew_formatted))[:, :, :3] * 255).astype(np.uint8)\n",
    "\n",
    "    meta.update({\"count\":3})\n",
    "\n",
    "\n",
    "    with rasterio.open(output_colored_tiff_filename, 'w', **meta) as dst:\n",
    "        reshape = reshape_as_raster(coloured_data)\n",
    "        dst.write(reshape)\n",
    "\n",
    "try:\n",
    "    dst_profile = cog_profiles.get('deflate')\n",
    "    with MemoryFile() as mem_dst:\n",
    "        cog_translate(\n",
    "            output_colored_tiff_filename,\n",
    "            output_cog_filename,\n",
    "            config=dst_profile,\n",
    "            in_memory=True,\n",
    "            dtype=\"uint8\",\n",
    "            add_mask=False,\n",
    "            nodata=0,\n",
    "            dst_kwargs=dst_profile\n",
    "        )\n",
    "    \n",
    "    save_metadata_sidecar(output_cog_filename, asset_metadata)    \n",
    "except:\n",
    "    raise Exception('Unable to convert to cog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
